{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x2bd1c760730>,\n",
       " 'date': '2010-01-01',\n",
       " 'id': 1,\n",
       " 'tobs': 65.0,\n",
       " 'station': 'USC00519397',\n",
       " 'prcp': 0.08}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_table = session.query(Measurement).first()\n",
    "m_table.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '2010-01-01', 65.0, 0.08, 'USC00519397')\n",
      "(2, '2010-01-02', 63.0, 0.0, 'USC00519397')\n",
      "(3, '2010-01-03', 74.0, 0.0, 'USC00519397')\n",
      "(4, '2010-01-04', 76.0, 0.0, 'USC00519397')\n",
      "(5, '2010-01-06', 73.0, None, 'USC00519397')\n",
      "(6, '2010-01-07', 70.0, 0.06, 'USC00519397')\n",
      "(7, '2010-01-08', 64.0, 0.0, 'USC00519397')\n",
      "(8, '2010-01-09', 68.0, 0.0, 'USC00519397')\n",
      "(9, '2010-01-10', 73.0, 0.0, 'USC00519397')\n",
      "(10, '2010-01-11', 64.0, 0.01, 'USC00519397')\n"
     ]
    }
   ],
   "source": [
    "#measurements table rows\n",
    "\n",
    "for row in session.query(Measurement.id, Measurement.date, Measurement.tobs, Measurement.prcp, Measurement.station).limit(10).all():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x2bd1c7746d0>,\n",
       " 'latitude': 21.2716,\n",
       " 'station': 'USC00519397',\n",
       " 'longitude': -157.8168,\n",
       " 'id': 1,\n",
       " 'name': 'WAIKIKI 717.2, HI US',\n",
       " 'elevation': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_table = session.query(Station).first()\n",
    "s_table.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'WAIKIKI 717.2, HI US', 'USC00519397', -157.8168, 21.2716, 3.0)\n",
      "(2, 'KANEOHE 838.1, HI US', 'USC00513117', -157.8015, 21.4234, 14.6)\n",
      "(3, 'KUALOA RANCH HEADQUARTERS 886.9, HI US', 'USC00514830', -157.8374, 21.5213, 7.0)\n",
      "(4, 'PEARL CITY, HI US', 'USC00517948', -157.9751, 21.3934, 11.9)\n",
      "(5, 'UPPER WAHIAWA 874.3, HI US', 'USC00518838', -158.0111, 21.4992, 306.6)\n",
      "(6, 'WAIMANALO EXPERIMENTAL FARM, HI US', 'USC00519523', -157.71139, 21.33556, 19.5)\n",
      "(7, 'WAIHEE 837.5, HI US', 'USC00519281', -157.84888999999998, 21.45167, 32.9)\n",
      "(8, 'HONOLULU OBSERVATORY 702.2, HI US', 'USC00511918', -157.9992, 21.3152, 0.9)\n",
      "(9, 'MANOA LYON ARBO 785.2, HI US', 'USC00516128', -157.8025, 21.3331, 152.4)\n"
     ]
    }
   ],
   "source": [
    "for row in session.query(Station.id, Station.name, Station.station, Station.longitude, Station.latitude, Station.elevation).all():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the inspector and connect it to the engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Collect the names of tables within the database\n",
    "inspector.get_table_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the inspector to print the column names within the 'measuremnts' table and its types\n",
    "columns1 = inspector.get_columns('measurements')\n",
    "\n",
    "for column in columns1:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id INTEGER\n",
      "station TEXT\n",
      "name TEXT\n",
      "latitude FLOAT\n",
      "longitude FLOAT\n",
      "elevation FLOAT\n"
     ]
    }
   ],
   "source": [
    "# Using the inspector to print the column names within the 'station' table and its types\n",
    "columns2 = inspector.get_columns('station')\n",
    "\n",
    "for column in columns2:\n",
    "    print(column[\"name\"], column[\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************* Precipitation Analysis ********************* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-08-23',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "\n",
    "#calulation the last date.\n",
    "session.query(Measurement.date).order_by(Measurement.date.desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Date: 2016-08-22\n"
     ]
    }
   ],
   "source": [
    "# Calculate the date 1 year ago from the last data point in the database\n",
    "year_ago_date= dt.date(2017, 8, 23) - dt.timedelta(days=366)\n",
    "print('Query Date:', year_ago_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2016-08-23', 0.0),\n",
       " ('2016-08-23', 0.15),\n",
       " ('2016-08-23', 0.05),\n",
       " ('2016-08-23', None),\n",
       " ('2016-08-23', 0.02),\n",
       " ('2016-08-23', 1.79),\n",
       " ('2016-08-23', 0.7),\n",
       " ('2016-08-24', 0.08),\n",
       " ('2016-08-24', 2.15),\n",
       " ('2016-08-24', 2.28)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a query to retrieve the data and precipitation scores\n",
    "\n",
    "prcp_date = session.query(Measurement.date, Measurement.prcp).\\\n",
    "            filter(func.strftime('%Y-%m-%d',Measurement.date) > year_ago_date).order_by(Measurement.date).limit(10).all()\n",
    "prcp_date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "\n",
    "prcp_df = pd.DataFrame(prcp_date, columns=['date', 'prcp'])\n",
    "prcp_df.set_index('date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by date\n",
    "\n",
    "sort_df = prcp_df.sort_values('date')\n",
    "sort_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp_df.plot(title=\"Precipitation Analysis\", figsize=(12,8))\n",
    "plt.legend(loc='upper center')\n",
    "#plt.savefig(\"Images/precipitation.png\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "prcp_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************* Station Analysis ********************* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "number_of_stations = session.query(Station).count()\n",
    "number_of_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "active_stations = (session.query(Measurement.station, func.count(Measurement.station))\n",
    "                    .group_by(Measurement.station)\n",
    "                    .order_by(func.count(Measurement.station).desc()).all())\n",
    "active_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature of the most active station?\n",
    "\n",
    "tobs = [Measurement.station, func.min(Measurement.tobs),\n",
    "       func.max(Measurement.tobs),func.avg(Measurement.tobs)]\n",
    "\n",
    "activeStation = session.query(*tobs).filter(Measurement.station=='USC00519281').all()\n",
    "activeStation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(activeStation, columns=['station', 'min_temp', 'max_temp', 'avg_temp']).set_index('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "#year_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "year_high_temp =(session.query(Measurement.date,(Measurement.tobs))\n",
    "                  .filter(func.strftime(Measurement.date) > year_ago_date)\n",
    "                  .filter(Measurement.station=='USC00519281')\n",
    "                  .all())\n",
    "year_high_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_df = pd.DataFrame(year_high_temp, columns=['date', 'temp']) \n",
    "tobs_df.set_index('date', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,7)\n",
    "\n",
    "plt.hist(tobs_df['temp'], bins=12, alpha=0.6 )\n",
    "\n",
    "plt.title('Temperature Observation Aug 2016 - Aug 2017\\nHonolulu, Hawaii',fontsize=20)\n",
    "plt.xlabel('Temperature (F)',fontsize=16)\n",
    "plt.ylabel('Frequency',fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylim(0,70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH WORK FOR APP.PY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, jsonify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def precipitation():\n",
    "#     # Create session (link) from Python to the DB\n",
    "#     session = Session(engine)\n",
    "\n",
    "#     # Query Measurement\n",
    "#     results = (session.query(Measurement.date, Measurement.prcp)\n",
    "#                       .order_by(Measurement.date))\n",
    "    \n",
    "#     # Create a dictionary\n",
    "#     precipitation_date = []\n",
    "#     for each_row in results:\n",
    "#         dt_dict = {}\n",
    "#         dt_dict[\"date\"] = each_row.date\n",
    "#         dt_dict[\"prcp\"] = each_row.prcp\n",
    "#         precipitation_date.append(dt_dict)\n",
    "\n",
    "# #     return jsonify(precipitation_date)\n",
    "#     return(precipitation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precipitation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def tobs():\n",
    "    \n",
    "# #create a session\n",
    "# session3 = Session(engine)\n",
    "\n",
    "# # Query measurement for latest datre \n",
    "# last_date = session3.query(Measurement.date).order_by(Measurement.date.desc()).first()\n",
    "\n",
    "# print(last_date)\n",
    "# last_12mnth = (dt.datetime.strptime(last_date[0],'%Y-%m-%d') -dt.timedelta(days=365)).date()\n",
    "# print(last_12mnth)\n",
    "\n",
    "# #  year_ago_date= dt.date(2017, 8, 23) - dt.timedelta(days=366)\n",
    "# # # print('Query Date:', year_ago_date)\n",
    "\n",
    "# tobs_results = session3.query(Measurement.date, Measurement.tobs).\\\n",
    "# filter(Measurement.date >= last_12mnth).order_by(Measurement.date).all()\n",
    "\n",
    "# # Create a list of dicts with `date` and `tobs` as the keys and values\n",
    "# tobs_totals = []\n",
    "# for result in tobs_results:\n",
    "#     row = {}\n",
    "#     row[\"date\"] = result[0]\n",
    "#     row[\"tobs\"] = result[1]\n",
    "#     tobs_totals.append(row)\n",
    "\n",
    "# tobs_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def start_date(start):\n",
    "#    # print(\"start_date status:OK\")\n",
    "#     #convert the tsring from user to date\n",
    "#     start_date = dt.datetime.strptime(start, '%Y-%m-%d').date()\n",
    "#     last_date_dd = (dt.datetime.strptime(last_date[0][0], '%Y-%m-%d')).date() \n",
    "#     first_date_dd = (dt.datetime.strptime(first_date[0][0], '%Y-%m-%d')).date()\n",
    "#     #if fgiven start_date greater than last or lesser than first available date in dataset, print the following \n",
    "#     if start_date > last_date_dd or start_date < first_date_dd:\n",
    "#         return(f\"Select date range between {first_date[0][0]} and {last_date[0][0]}\")\n",
    "#     else:\n",
    "#         #Return a JSON list of the minimum temperature, the average temperature, \n",
    "#         #and the max temperature for a given start range.\n",
    "#         start_min_max_temp = session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs),\\\n",
    "#             func.max(Measurement.tobs)).filter(Measurement.date >= start_date).all()\n",
    "#         start_date_data = list(np.ravel(start_min_max_temp))\n",
    "#         #return jsonify(start_date_data)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
